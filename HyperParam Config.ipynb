{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799e7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hyperparameter configurations stored as dictionaries\n",
    "Random search space + 3 configurations of\n",
    "RNN reported in paper https://arxiv.org/pdf/1708.03513.pdf\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from .useful import merge_two_dicts\n",
    "\n",
    "#Parameters fixed for all experiments\n",
    "fixed_parameters = {\n",
    "    \"layer_type\": [\"GRU\"],          # recurrent_unit\n",
    "    \"loss\": [\"binary_crossentropy\"], #loss function\n",
    "    \"kernel_initializer\": [\"lecun_uniform\"],  #initialise input weights with recommended from http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n",
    "    \"recurrent_initializer\": [\"lecun_uniform\"], # initialise recurrent weights with recommended from http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n",
    "    \"activation\": [\"sigmoid\"],      # Activation functin of Dense output layer\n",
    "    \"recurrent_dropout\": [0]\n",
    "}\n",
    "\n",
    "def get_all():\n",
    "    \"\"\"Return dict of possible values,\n",
    "    possible values can be stored as a list --> equal probability of chosing any option\n",
    "    or as a dictionary with relative probabilities stored to weight choices e.g. for weight merge_two_dicts rule\"\"\"\n",
    "    all_options =  {\n",
    "        \"depth\": [1,2,3],           # number of hidden layers\n",
    "        \"bidirectional\": [True, False], # bidirectional hidden layers\n",
    "        \"hidden_neurons\": list(range(1, 501)), #number of hidden neurons\n",
    "        \"optimiser\": [\"adam\"],\n",
    "        \"dropout\": [0] * 3 + [0.1,0.2,0.3,0.4,0.5], #list(np.arange(0, 0.51, 0.1)), #dropout rate\n",
    "        \"b_l1_reg\": [0, 0.01],          # bias regulariser (l1)\n",
    "        \"b_l2_reg\": [0, 0.01],          # bias regulariser (l2)\n",
    "        \"r_l1_reg\": [0, 0.01],          #  weight regulariser (l1)\n",
    "        \"r_l2_reg\": [0, 0.01],          #  weight regulariser (l2)\n",
    "        \"epochs\": list(range(1, 100)), #501)),  # number of training epochs\n",
    "        \"sequence_length\": list(range(1, 21)),\n",
    "        \"batch_size\": [32*(2**i) for i in range(5)] ,\n",
    "        \"recurrent_dropout\": [0] * 3 + [0.1,0.2,0.3,0.4,0.5]\n",
    "    }\n",
    "    return merge_two_dicts(all_options, fixed_parameters)\n",
    "\n",
    "def get_A():\n",
    "    \"\"\"Return dictionary of parameters for\n",
    "    config A in https://arxiv.org/pdf/1708.03513.pdf\"\"\"\n",
    "    A = {\n",
    "        \"depth\": [3],\n",
    "        \"bidirectional\": [True],\n",
    "        \"hidden_neurons\": [74],\n",
    "        \"learning_rate\": [0.001],\n",
    "        \"optimiser\": [\"adam\"],\n",
    "        \"dropout\": [0.3],\n",
    "        \"b_l1_reg\": [0],\n",
    "        \"b_l2_reg\": [0],\n",
    "        \"r_l1_reg\": [0],\n",
    "        \"r_l2_reg\": [0.01],\n",
    "        \"epochs\": [53],\n",
    "        \"sequence_length\": list(range(1, 31)),\n",
    "        \"batch_size\": [64],\n",
    "        \"description\": [\"A\"],\n",
    "    }\n",
    "    return merge_two_dicts(A, fixed_parameters)\n",
    "\n",
    "def get_B():\n",
    "    \"\"\"Return dictionary of parameters for\n",
    "    config B in https://arxiv.org/pdf/1708.03513.pdf\"\"\"\n",
    "    B = {\n",
    "        \"depth\": [1],\n",
    "        \"bidirectional\": [True],\n",
    "        \"hidden_neurons\": [358],\n",
    "        \"learning_rate\": [0.001],\n",
    "        \"optimiser\": [\"adam\"],\n",
    "        \"dropout\": [0.1],\n",
    "        \"b_l1_reg\": [0],\n",
    "        \"b_l2_reg\": [0],\n",
    "        \"r_l1_reg\": [0],\n",
    "        \"r_l2_reg\": [0.01],\n",
    "        \"epochs\": [112],\n",
    "        \"sequence_length\": list(range(1, 21)),\n",
    "        \"batch_size\": [64],\n",
    "        \"description\": [\"B\"],\n",
    "    }\n",
    "    return merge_two_dicts(B, fixed_parameters)\n",
    "\n",
    "def get_C():\n",
    "    \"\"\"Return dictionary of parameters for\n",
    "    config C in https://arxiv.org/pdf/1708.03513.pdf\"\"\"\n",
    "    C = {\n",
    "        \"depth\": [2],\n",
    "        \"bidirectional\": [False],\n",
    "        \"hidden_neurons\": [195],\n",
    "        \"learning_rate\": [0.001],\n",
    "        \"optimiser\": [\"adam\"],\n",
    "        \"dropout\": [0.1],\n",
    "        \"b_l1_reg\": [0],\n",
    "        \"b_l2_reg\": [0],\n",
    "        \"r_l1_reg\": [0.01],\n",
    "        \"r_l2_reg\": [0],\n",
    "        \"epochs\": [39],\n",
    "        \"sequence_length\": list(range(1, 31)),\n",
    "        \"batch_size\": [64],\n",
    "        \"description\": [\"C\"],\n",
    "    }\n",
    "    return merge_two_dicts(C, fixed_parameters)\n",
    "\n",
    "def get_A_B_C():\n",
    "    \"\"\"return top 3 configurations as dictionary values\"\"\"\n",
    "    return {\n",
    "        \"A\": get_A(),\n",
    "        \"B\": get_B(),\n",
    "        \"C\": get_C(),\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
